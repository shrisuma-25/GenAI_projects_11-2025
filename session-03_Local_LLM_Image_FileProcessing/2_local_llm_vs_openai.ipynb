{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d637d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def ask_question_local_llm(prompt):\n",
    "    # print(f\"User asked: {prompt}\")\n",
    "    # my_client.chat.completions.create\n",
    "\n",
    "    # Run a prompt against a local model (e.g., llama2)\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assitant - Respond in one line\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64bc6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "my_client = OpenAI(api_key=my_api_key)\n",
    "# my_client\n",
    "\n",
    "def ask_question_open_ai(prompt):\n",
    "\n",
    "    # print(f\"User asked: {prompt}\")\n",
    "    # my_client.chat.completions.create\n",
    "\n",
    "    llm_response = my_client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer as concisely as possible.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return llm_response.choices[0].message.content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c0cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from local LLM: The capital of France is Paris.\n",
      "Response from OpenAI: Paris\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "response_local_llm = ask_question_local_llm(prompt)\n",
    "response_open_ai = ask_question_open_ai(prompt)\n",
    "\n",
    "print(f\"Response from local LLM: {response_local_llm}\")\n",
    "print(f\"Response from OpenAI: {response_open_ai}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0876978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OPEN AI RESPONSE-------------------\n",
      "Time taken by OpenAI: 19.824151039123535 seconds\n",
      "\n",
      "OpenAI says: None in Python is of type NoneType. Most “NoneType” errors come from calling methods or indexing on None, or from functions that return None when you expected a value. Common errors include AttributeError: 'NoneType' object has no attribute '...' and TypeError: 'NoneType' object is not subscriptable or has no len().\n",
      "\n",
      "Ways to handle it:\n",
      "\n",
      "- Explicit guard (preferred)\n",
      "  - if value is None: raise ValueError(\"value must not be None\") or return a sensible default\n",
      "  - Example:\n",
      "    def process(data):\n",
      "        if data is None:\n",
      "            raise ValueError(\"data cannot be None\")\n",
      "        return len(data)\n",
      "\n",
      "- Provide a default for None\n",
      "  - if value is None: value = default\n",
      "  - Example:\n",
      "    def greet(name):\n",
      "        if name is None:\n",
      "            name = \"guest\"\n",
      "        return f\"Hello, {name}!\"\n",
      "\n",
      "- Use typing to catch None earlier\n",
      "  - from typing import Optional\n",
      "  - def length(s: Optional[str]) -> int:\n",
      "        if s is None:\n",
      "            return 0\n",
      "        return len(s)\n",
      "\n",
      "- Safe attribute access and dict lookups\n",
      "  - email = getattr(user, \"email\", None)  # None if missing\n",
      "  - city = data.get(\"city\")  # returns None if missing; handle as needed\n",
      "\n",
      "- Validate at the start and avoid silent None returns\n",
      "  - def divide(a, b):\n",
      "        if b is None:\n",
      "            raise ValueError(\"b cannot be None\")\n",
      "        if b == 0:\n",
      "            raise ZeroDivisionError(\"division by zero\")\n",
      "        return a / b\n",
      "\n",
      "- Don’t rely on truthiness for defaults\n",
      "  - x or y can fail if x can be 0, \"\", False. Use explicit None checks.\n",
      "\n",
      "- Debug tips\n",
      "  - print(type(x)) or type(None) to confirm\n",
      "  - Use assertions in dev: assert x is not None\n",
      "  - Use static type checkers (mypy, pyright) with Optional to catch None issues\n",
      "\n",
      "- If you truly want to handle a potentially None result from a chain\n",
      "  - result = maybe_none()\n",
      "  - if result is not None: do_something(result)\n",
      "\n",
      "If you share a snippet causing a NoneType error, I can propose a targeted fix.\n",
      "\n",
      "\n",
      "-------------------LOCAL LLM RESPONSE-------------------\n",
      "Time taken by Local LLM: 7.669388055801392 seconds\n",
      "\n",
      "Local LLM says: In Python, you can handle the `NoneType` exception by checking if an object is `None` before attempting to access its attributes or methods using `if obj is not None:` or by using a try-except block with a specific exception type of `AttributeError` for instance.\n",
      "-------------------OPEN AI RESPONSE-------------------\n",
      "Time taken by OpenAI: 12.873746871948242 seconds\n",
      "\n",
      "OpenAI says: Here are the extracted details:\n",
      "\n",
      "- Topic: US jobs/hiring, inflation, and labor-market policy uncertainty.\n",
      "- Timeframe: This year; jobs lost in June and August; three-month period ending in September.\n",
      "- Key metrics:\n",
      "  - June: jobs lost.\n",
      "  - August: jobs lost.\n",
      "  - Three-month average job gains (ending September): about 62,000.\n",
      "- Causes/Context: Firms hesitant to hire or invest due to uncertainty about President Donald Trump’s sweeping economic policies.\n",
      "- Source of data: Labor Department.\n",
      "- Affected parties: US companies (hiring/investing), policymakers managing inflation and the labor market, Trump administration policies.\n",
      "\n",
      "\n",
      "-------------------LOCAL LLM RESPONSE-------------------\n",
      "Time taken by Local LLM: 5.092545986175537 seconds\n",
      "\n",
      "Local LLM says: The US economy is experiencing a slowdown in hiring, with companies hesitant to invest due to uncertainty surrounding President Trump's economic policies, leading to job losses in June and August and an average pace of job gains of around 62,000 for three months ending in September.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    # Ask user for a question\n",
    "    user_prompt = input(\"Ask something: \")\n",
    "\n",
    "    if (user_prompt.lower() != 'quit'):\n",
    "        # Get and print the response\n",
    "        print (\"-------------------OPEN AI RESPONSE-------------------\")\n",
    "        start = time.time()\n",
    "        response_openai = ask_question_open_ai(user_prompt)\n",
    "        end = time.time()   \n",
    "        print(f\"Time taken by OpenAI: {end - start} seconds\")\n",
    "        print(\"\\nOpenAI says:\", response_openai)\n",
    "\n",
    "        print (\"\\n\\n-------------------LOCAL LLM RESPONSE-------------------\")\n",
    "        start = time.time()\n",
    "        response_local = ask_question_local_llm(user_prompt)\n",
    "        end = time.time()   \n",
    "        print(f\"Time taken by Local LLM: {end - start} seconds\")\n",
    "        print(\"\\nLocal LLM says:\", response_local)        \n",
    "\n",
    "        # add delay of 3 seconds\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"Exiting...\")\n",
    "        break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
